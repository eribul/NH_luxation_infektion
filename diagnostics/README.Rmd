---
title: "External validation"
author: "Erik Bulow"
date: '`r Sys.Date()`'
output: 
#  github_document:
#    toc: yes
#    df_print: "kable"
  html_document:
    toc: yes
    df_print: "kable"
    toc_float: yes
    number_sections: yes
    code_folding: "hide"
    keep_md: yes
bibliography: 
  # C:\\Users\\erik_\\Documents\\library.bib
  H:\\zotero_lib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

load("../cache/ext_val_required_data.RData")
load("../cache/tab_categorization.RData")
load("../cache/df.RData")
```

# Start

Install and attach some useful packages

```{r}
# First, set random seed for reproducability:
set.seed(123)

# USeful packages
pkgs <- c("tidyverse", "doParallel", "pROC", "rms", "givitiR")

# Install if not already installed
pkgsinst <- setdiff(pkgs, rownames(installed.packages()))
if (length(pkgsinst)) install.packages(pkgsinst)

# Attatch
purrr::walk(pkgs, ~suppressPackageStartupMessages(library(., character.only = TRUE)))
```

Load the exported models to validate (also found "manually" at [Github](https://github.com/eribul/NH_luxation_infektion/blob/master/cache/ext_val_required_data.RData)). This is a nested data frame with one row for each prediction period (90 days and 2 years). Column `fit` contains `glm` objects stripped from any personal patient data.

```{r}
# Load the exported model object
load("../cache/fit_brl_reduced_lean.RData")
```

Let's inspect the model for 90 days just to get a sence of it:

```{r}
fit_brl_reduced_lean$fit[[1]]
```

We should now use this model with the `predict` function combined with new data from Denmark. So, how should this data look like?

# Prepare data

## Inclusion/exlusion

Those were the inclusions/exclusions from Sweden. Similar criteria should apply also for the external validation data set to get comparable cohorts.

Ignore filtering of missing educational level, hospital type and fixation, however, since those variables are not needed in the model to validate.

```{r}
knitr::include_graphics("../graphs/flowchart.png")
```

# Variables

## Outcome

The outcome variables are simply called `outcome` in each model (hence, adjusted for each model). Those are logical/boolean (or 0/1-numeric) indicating whether the patient got PJI within 90 days (2 years) after THA (`TRUE`/1) or not (`FALSE`/0). Note that we had previously excluded all patients who died within two years. A competing risk model for survival analysis might be better but we were pragmatic in this case.

We identified PJI within 90 days/2 years as either the primary or secondary reson for reoperation performed within this time frame, as recorded to SHAR, or if a relevant ICD-10/NOMESCO code was recorded during a hospitl visit/admission during this period.

We used regular expression to identify such codes:

```{r}
coder::hip_ae_hailer %>% 
  filter(group == "Infection")
```

## Predictors

The data to evaluate (in addition to the respective `outcome` variable) should look like this:

```{r}
head(ext_val_required_data) 
```

thus with columns:

```{r}
names(ext_val_required_data)
```

Some of those are factor variables:

```{r}
ext_val_required_data %>% 
  select(where(is.factor)) %>% 
  pivot_longer(everything(), values_ptypes = list(value = character())) %>% 
  distinct() %>% 
  arrange(name, value) %>% 
  group_by(name) %>% 
  mutate(name = replace(name, duplicated(name), ""))
```

-   `P_Sex` and `P_ASA` should be self-explanatory
-   `P_BMI` is a broader categorization based on BMI and the [WHO classification] (<https://www.euro.who.int/en/health-topics/disease-prevention/nutrition/a-healthy-lifestyle/body-mass-index-bmi>) where overweight = "pre-obesity"  
-   `P_DiaGrp` is based on ICD-10 codes recorded in SHAR and grouped into broader categories.

```{r}
readr::read_csv2("../data/P_DiaGrp.csv", trim_ws = TRUE)
```

## Comorbidities

Variables prefixed by `c_`:

```{r}
nms     <- names(ext_val_required_data)
comorbs <- nms[startsWith(nms, "c_")]
comorbs
```

... are logical/boolean indicators of comorbidities based on ICD-10/ATC codes from one year prior to THA, as recorded in our National Patient Register and medical prescription register. Individual codes were grouped according to Charlson and Elixhauser as codified by table 2 in \@Quan2005, and as RxRisk V according to table 1 in \@Pratt2018. Those conditions were then further combined according to table 1 in the drafted manuscript:

```{r}
comorbs_nms <- 
  comorbs %>% 
  tolower() %>% 
  {gsub("^c_", "", .)} %>%
  {gsub("_", " ", .)}

tab_categorization %>% 
  filter(
    tolower(`Comorbidities by groups`) %in% comorbs_nms
  )
```

## Example validation for model of 90 days

We have the 90 day model from the shared R object;

```{r}
model <- fit_brl_reduced_lean$fit[[1]]
```

Let's assume we now have the `outcome` variable and a data frame `X` with the predictors (I will use the Swedish data just as an example but this should of course be changed for the external validation).

```{r}
outcome <- df$outcome_infection_90d
X       <- ext_val_required_data
```

# Validation of model as is

```{r}
# Tibble with observed and predicted outcome
obspred <- 
  tibble(
    obs  = outcome, 
    pred = predict(model, X, type = "response")
  )

# ROC curve
ROC <- pROC::roc(obspred, "obs", "pred", direction = "<")

# Estimate CI for AUC based on bootstrapping
# Use parallel processing to speed up the process
doParallel::registerDoParallel()
AUCci <- 
  pROC::ci.auc(
    ROC, 
    method          = "bootstrap", 
    boot.n          = 100,     # Remove this argument and use the default!
    boot.stratified = FALSE, 
    parallel        = TRUE
  )


# Check calibration. Note that devel should actually be "internal" for this example but I use
# "external", since that's what you will use for the external validation. 
calibration <- 
  givitiR::givitiCalibrationBelt(
    as.numeric(obspred$obs), 
    obspred$pred, 
    devel = "external"
  )
```

## Results

For this example we had AUC:

```{r}
AUCci
plot(ROC)
```

```{r}
plot(calibration, xlim = c(0, 0.3), ylim = c(0, 0.3))
```

# Re-calibrated intercept

Method 2 from table 1 in \@Steyerbeg2004.

```{r}
Z <- predict(model, X, type = "response")
  
# Refit the intercept using Z = a + Xb from above as offset
fit2 <- glm(outcome ~ 1, offset = Z)

# Same calibration and validation as above
obspred2     <- tibble(obs  = outcome, pred = predict(fit2, type = "response"))
ROC2         <- pROC::roc(obspred2, "obs", "pred", direction = "<")
AUCci2 <- 
  pROC::ci.auc(
    ROC2, 
    method = "bootstrap", 
    boot.n = 100,     # Remove this argument and use the default!
    boot.stratified = FALSE, 
    parallel = TRUE
  )

calibration2 <- 
  givitiR::givitiCalibrationBelt(
    as.numeric(obspred2$obs), 
    obspred2$pred, 
    devel = "external"
  )
```

## Results

```{r}
AUCci2
plot(ROC2)
plot(calibration2, xlim = c(0, 0.03), ylim = c(0, 0.06))
```

# Re-calibration of intercenpt and calibration slope

Method 3 from table 1 in \@Steyerberg2004.

```{r}
fit3         <- glm(outcome ~ 1 + Z)
obspred3     <- tibble(obs  = outcome, pred = predict(fit3, type = "response"))
ROC3         <- pROC::roc(obspred3, "obs", "pred", direction = "<")

AUCci3 <- 
  pROC::ci.auc(
    ROC3, 
    method = "bootstrap", 
    boot.n = 100,     # Remove this argument and use the default!
    boot.stratified = FALSE, 
    parallel = TRUE
  )

calibration3 <- 
  givitiR::givitiCalibrationBelt(
    as.numeric(obspred3$obs), 
    obspred3$pred, 
    devel = "external"
  )
```

## Results

```{r}
AUCci3
plot(ROC3)
plot(calibration3, xlim = c(0, 0.03), ylim = c(0, 0.06))
```

# Export data to Sweden

## ROC

If it would be OK to export coordinates for ROC-plots I would recommend this code to extract only the minimal data needed:

```{r}

roc_plot_coords <- 
  tibble(
    model = c("ias is", "re-calibrated intercept", "recalibrated"),
    data = 
      list( 
        tibble(
          specificities = ROC$specificities, 
          sensitivities = ROC$sensitivities
        ),
        tibble(
          specificities = ROC2$specificities, 
          sensitivities = ROC2$sensitivities
        ),
        tibble(
          specificities = ROC3$specificities, 
          sensitivities = ROC3$sensitivities
        )
      )
  )

```

## AUC with CI

The text output from `AUCci`, `AUCci2` and `AUCci3` should be enough. Hence, the same character string that gets printed above (but now stored in an object).

```{r}
AUCci_print  <- capture.output(AUCci)
AUCci2_print <- capture.output(AUCci2)
AUCci3_print <- capture.output(AUCci3)
```

## Export objects

Save objects above to file `export_90d.RData` (in the current working directory).

```{r}
save(
  roc_plot_coords,
  AUCci_print,
  AUCci2_print,
  AUCci3_print,
  calibration,
  calibration2,
  calibration3,
  file = "export_90d.RData"
)
```

# 2 years

Repeat for the 2-year model.

# Bibliography
